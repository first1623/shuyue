import os
import re
import json
import yaml
from typing import Dict, List, Any, Tuple, Optional
from pathlib import Path
from dataclasses import dataclass, asdict
from datetime import datetime
import ast

@dataclass
class Prompt:
    id: str
    content: str
    source_file: str
    line_number: int
    purpose: str  # 'debugging', 'code_generation', 'review', 'testing', 'documentation', 'planning'
    domain: str  # 'frontend', 'backend', 'devops', 'data_science', 'general'
    complexity: str  # 'simple', 'intermediate', 'advanced'
    context_type: str  # 'project_specific', 'generic', 'reusable'
    tags: List[str]
    created_at: str
    usage_count: int = 0
    effectiveness_rating: float = 0.0

class PromptCollector:
    """æç¤ºè¯æ”¶é›†å’Œæ•´ç†å·¥å…·"""
    
    def __init__(self, project_path: str = "."):
        self.project_path = Path(project_path)
        self.discovered_prompts: List[Prompt] = []
        self.prompt_library = {}
        self.pattern_config = self._load_pattern_config()
        
    def _load_pattern_config(self) -> Dict:
        """åŠ è½½æç¤ºè¯è¯†åˆ«æ¨¡å¼é…ç½®"""
        return {
            'comment_patterns': {
                'python': [
                    r'#\s*[Pp]rompt:\s*(.+)$',
                    r'#\s*[Ii]nstruction:\s*(.+)$', 
                    r'#\s*[Gg]uide:\s*(.+)$',
                    r'#\s*[Tt]emplate:\s*(.+)$',
                    r'#\s*[Dd]ebug.*?:\s*(.+)$',
                    r'#\s*[Ff]ix.*?:\s*(.+)$'
                ],
                'javascript': [
                    r'//\s*[Pp]rompt:\s*(.+)$',
                    r'//\s*[Ii]nstruction:\s*(.+)$',
                    r'//\s*[Tt]odo.*?:\s*(.+)$',
                    r'/\*\s*[Pp]rompt:\s*(.+?)\*/',
                    r'/\*\s*[Gg]uide:\s*(.+?)\*/'
                ],
                'general': [
                    r'<!--\s*[Pp]rompt:\s*(.+?)-->',
                    r'<!--\s*[Ii]nstruction:\s*(.+?)-->',
                    r'\/\/\s*[Pp]rompt:\s*(.+)$',
                    r'%.*?[Pp]rompt:\s*(.+)$'
                ]
            },
            'doc_patterns': {
                'markdown': [
                    r'^##\s*[Pp]rompt[s]?\s*$\n(.*?)(?=\n##|\n#|$)',
                    r'^###\s*[Ii]nstruction[s]?\s*$\n(.*?)(?=\n###|\n##|\n#|$)',
                    r'\*\*[Pp]rompt\*\*:\s*(.+)$',
                    r'>\s*[Nn]ote[:\s]*(.+)$'
                ],
                'text': [
                    r'[Pp]rompt[:\s]*(.+)$',
                    r'[Ii]nstruction[:\s]*(.+)$',
                    r'[Gg]uide[:\s]*(.+)$',
                    r'[Tt]emplate[:\s]*(.+)$'
                ]
            },
            'config_patterns': {
                'json': [
                    r'"[Pp]rompt"\s*:\s*"([^"]+)"',
                    r'"[Ii]nstruction"\s*:\s*"([^"]+)"',
                    r'"[Gg]uide"\s*:\s*"([^"]+)"'
                ],
                'yaml': [
                    r'[Pp]rompt:\s*(.+)',
                    r'[Ii]nstruction:\s*(.+)',
                    r'[Gg]uide:\s*(.+)'
                ]
            }
        }
    
    async def scan_project_for_prompts(self, file_types: List[str] = None, 
                                     exclude_dirs: List[str] = None) -> List[Prompt]:
        """æ‰«æé¡¹ç›®ä¸­çš„æç¤ºè¯"""
        print("ğŸ” å¼€å§‹æ‰«æé¡¹ç›®ä¸­çš„æç¤ºè¯...")
        
        if file_types is None:
            file_types = ['py', 'js', 'ts', 'md', 'txt', 'json', 'yml', 'yaml', 'java', 'cpp', 'c']
        
        if exclude_dirs is None:
            exclude_dirs = ['node_modules', '.git', '__pycache__', 'venv', '.venv', 'dist', 'build']
        
        self.discovered_prompts = []
        
        for file_type in file_types:
            files = list(self.project_path.rglob(f"*.{file_type}"))
            
            for file_path in files:
                # è·³è¿‡æ’é™¤çš„ç›®å½•
                if any(excluded in str(file_path) for excluded in exclude_dirs):
                    continue
                    
                try:
                    prompts = await self.extract_prompts_from_file(file_path)
                    self.discovered_prompts.extend(prompts)
                except Exception as e:
                    print(f"æ‰«ææ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
        
        print(f"âœ… å‘ç° {len(self.discovered_prompts)} ä¸ªæç¤ºè¯")
        return self.discovered_prompts
    
    async def extract_prompts_from_file(self, file_path: Path) -> List[Prompt]:
        """ä»å•ä¸ªæ–‡ä»¶ä¸­æå–æç¤ºè¯"""
        prompts = []
        
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
                lines = content.split('\n')
                
            file_ext = file_path.suffix.lower()
            
            # æ ¹æ®æ–‡ä»¶ç±»å‹é€‰æ‹©æå–ç­–ç•¥
            if file_ext in ['.py', '.js', '.ts', '.java', '.cpp', '.c']:
                prompts.extend(self._extract_from_code_comments(content, lines, file_path, file_ext))
            elif file_ext in ['.md', '.txt']:
                prompts.extend(self._extract_from_documentation(content, file_path, file_ext))
            elif file_ext in ['.json']:
                prompts.extend(self._extract_from_json(content, file_path))
            elif file_ext in ['.yml', '.yaml']:
                prompts.extend(self._extract_from_yaml(content, file_path))
            else:
                prompts.extend(self._extract_from_generic_text(content, lines, file_path))
                
        except Exception as e:
            print(f"è¯»å–æ–‡ä»¶ {file_path} å¤±è´¥: {e}")
        
        return prompts
    
    def _extract_from_code_comments(self, content: str, lines: List[str], 
                                 file_path: Path, file_ext: str) -> List[Prompt]:
        """ä»ä»£ç æ³¨é‡Šä¸­æå–æç¤ºè¯"""
        prompts = []
        
        # ç¡®å®šæ–‡ä»¶ç±»å‹å¯¹åº”çš„æ¨¡å¼
        if file_ext == '.py':
            patterns = self.pattern_config['comment_patterns']['python']
        elif file_ext in ['.js', '.ts']:
            patterns = self.pattern_config['comment_patterns']['javascript']
        else:
            patterns = self.pattern_config['comment_patterns']['general']
        
        for line_num, line in enumerate(lines, 1):
            for pattern in patterns:
                matches = re.finditer(pattern, line, re.MULTILINE | re.DOTALL)
                for match in matches:
                    prompt_content = match.group(1).strip()
                    if len(prompt_content) > 10:  # è¿‡æ»¤å¤ªçŸ­çš„å†…å®¹
                        prompt = self._create_prompt_from_match(
                            prompt_content, file_path, line_num, 'code_comment'
                        )
                        prompts.append(prompt)
        
        return prompts
    
    def _extract_from_documentation(self, content: str, file_path: Path, 
                                   file_ext: str) -> List[Prompt]:
        """ä»æ–‡æ¡£ä¸­æå–æç¤ºè¯"""
        prompts = []
        
        if file_ext == '.md':
            patterns = self.pattern_config['doc_patterns']['markdown']
        else:
            patterns = self.pattern_config['doc_patterns']['text']
        
        for pattern in patterns:
            matches = re.finditer(pattern, content, re.MULTILINE | re.DOTALL)
            for match in matches:
                prompt_content = match.group(1).strip()
                if len(prompt_content) > 10:
                    # è®¡ç®—è¡Œå·
                    line_num = content[:match.start()].count('\n') + 1
                    prompt = self._create_prompt_from_match(
                        prompt_content, file_path, line_num, 'documentation'
                    )
                    prompts.append(prompt)
        
        return prompts
    
    def _extract_from_json(self, content: str, file_path: Path) -> List[Prompt]:
        """ä»JSONé…ç½®ä¸­æå–æç¤ºè¯"""
        prompts = []
        
        try:
            data = json.loads(content)
            prompts.extend(self._extract_from_dict_recursive(data, file_path, 'json'))
        except json.JSONDecodeError:
            pass
        
        return prompts
    
    def _extract_from_yaml(self, content: str, file_path: Path) -> List[Prompt]:
        """ä»YAMLé…ç½®ä¸­æå–æç¤ºè¯"""
        prompts = []
        
        try:
            data = yaml.safe_load(content)
            if data:
                prompts.extend(self._extract_from_dict_recursive(data, file_path, 'yaml'))
        except yaml.YAMLError:
            pass
        
        return prompts
    
    def _extract_from_dict_recursive(self, data: Dict, file_path: Path, 
                                   source_type: str, path: str = "") -> List[Prompt]:
        """é€’å½’ä»å­—å…¸ç»“æ„ä¸­æå–æç¤ºè¯"""
        prompts = []
        
        for key, value in data.items():
            current_path = f"{path}.{key}" if path else key
            
            # æ£€æŸ¥é”®åæ˜¯å¦æš—ç¤ºè¿™æ˜¯æç¤ºè¯
            if any(indicator in key.lower() for indicator in ['prompt', 'instruction', 'guide', 'template']):
                if isinstance(value, str) and len(value) > 10:
                    line_num = 1  # JSON/YAMLä¸ä¾¿äºç²¾ç¡®å®šä½è¡Œå·
                    prompt = self._create_prompt_from_match(
                        value, file_path, line_num, source_type, current_path
                    )
                    prompts.append(prompt)
            
            # é€’å½’å¤„ç†åµŒå¥—ç»“æ„
            if isinstance(value, dict):
                prompts.extend(self._extract_from_dict_recursive(value, file_path, source_type, current_path))
            elif isinstance(value, list):
                for i, item in enumerate(value):
                    if isinstance(item, dict):
                        prompts.extend(self._extract_from_dict_recursive(
                            item, file_path, source_type, f"{current_path}[{i}]"
                        ))
        
        return prompts
    
    def _extract_from_generic_text(self, content: str, lines: List[str], 
                                  file_path: Path) -> List[Prompt]:
        """ä»é€šç”¨æ–‡æœ¬ä¸­æå–æç¤ºè¯"""
        prompts = []
        
        # ç®€å•çš„å¯å‘å¼è§„åˆ™ï¼šå¯»æ‰¾åŒ…å«ç‰¹å®šå…³é”®è¯çš„è¡Œ
        prompt_indicators = ['prompt', 'instruction', 'guide', 'template', 'todo', 'fix', 'debug']
        
        for line_num, line in enumerate(lines, 1):
            line_lower = line.lower()
            if any(indicator in line_lower for indicator in prompt_indicators):
                # æ¸…ç†è¡Œå†…å®¹
                cleaned_line = re.sub(r'^[#\s/*>-]+', '', line).strip()
                if len(cleaned_line) > 15:
                    prompt = self._create_prompt_from_match(
                        cleaned_line, file_path, line_num, 'generic_text'
                    )
                    prompts.append(prompt)
        
        return prompts
    
    def _create_prompt_from_match(self, content: str, file_path: Path, 
                                line_num: int, source_type: str, 
                                config_path: str = "") -> Prompt:
        """ä»åŒ¹é…ç»“æœåˆ›å»ºPromptå¯¹è±¡"""
        # åˆ†ææç¤ºè¯çš„ç›®çš„å’Œé¢†åŸŸ
        purpose = self.analyze_prompt_purpose(content)
        domain = self.analyze_prompt_domain(content)
        complexity = self.analyze_prompt_complexity(content)
        context_type = self.analyze_context_type(content)
        tags = self.generate_tags(content, purpose, domain)
        
        prompt_id = f"{file_path.stem}_{source_type}_{line_num}_{hash(content) % 10000}"
        
        return Prompt(
            id=prompt_id,
            content=content,
            source_file=str(file_path),
            line_number=line_num,
            purpose=purpose,
            domain=domain,
            complexity=complexity,
            context_type=context_type,
            tags=tags,
            created_at=datetime.now().isoformat(),
            usage_count=0,
            effectiveness_rating=0.0
        )
    
    def analyze_prompt_purpose(self, content: str) -> str:
        """åˆ†ææç¤ºè¯çš„ç›®çš„"""
        content_lower = content.lower()
        
        purpose_keywords = {
            'debugging': ['debug', 'fix', 'error', 'bug', 'issue', 'problem'],
            'code_generation': ['create', 'generate', 'build', 'implement', 'write', 'make'],
            'review': ['review', 'check', 'examine', 'analyze', 'evaluate'],
            'testing': ['test', 'verify', 'validate', 'assert', 'mock'],
            'documentation': ['document', 'explain', 'describe', 'readme', 'comment'],
            'planning': ['plan', 'design', 'architect', 'structure', 'organize']
        }
        
        for purpose, keywords in purpose_keywords.items():
            if any(keyword in content_lower for keyword in keywords):
                return purpose
        
        return 'general'
    
    def analyze_prompt_domain(self, content: str) -> str:
        """åˆ†ææç¤ºè¯çš„é¢†åŸŸ"""
        content_lower = content.lower()
        
        domain_keywords = {
            'frontend': ['react', 'vue', 'angular', 'css', 'html', 'frontend', 'ui', 'ux'],
            'backend': ['api', 'server', 'database', 'backend', 'endpoint', 'service'],
            'devops': ['deploy', 'docker', 'kubernetes', 'ci/cd', 'pipeline', 'infrastructure'],
            'data_science': ['model', 'data', 'ml', 'ai', 'analysis', 'algorithm', 'training'],
            'mobile': ['mobile', 'ios', 'android', 'flutter', 'react native'],
            'security': ['security', 'auth', 'encrypt', 'permission', 'vulnerability']
        }
        
        for domain, keywords in domain_keywords.items():
            if any(keyword in content_lower for keyword in keywords):
                return domain
        
        return 'general'
    
    def analyze_prompt_complexity(self, content: str) -> str:
        """åˆ†ææç¤ºè¯çš„å¤æ‚åº¦"""
        word_count = len(content.split())
        
        if word_count < 15:
            return 'simple'
        elif word_count < 50:
            return 'intermediate'
        else:
            return 'advanced'
    
    def analyze_context_type(self, content: str) -> str:
        """åˆ†æä¸Šä¸‹æ–‡ç±»å‹"""
        # æ£€æŸ¥æ˜¯å¦åŒ…å«ç‰¹å®šé¡¹ç›®åç§°æˆ–è·¯å¾„
        if re.search(r'\b[A-Z][a-zA-Z]+Project\b|/[a-zA-Z_-]+/', content):
            return 'project_specific'
        elif any(word in content.lower() for word in ['generic', 'template', 'standard', 'common']):
            return 'generic'
        else:
            return 'reusable'
    
    def generate_tags(self, content: str, purpose: str, domain: str) -> List[str]:
        """ç”Ÿæˆæ ‡ç­¾"""
        tags = [purpose, domain]
        
        content_lower = content.lower()
        
        # æ·»åŠ æŠ€æœ¯æ ‡ç­¾
        tech_keywords = ['python', 'javascript', 'react', 'api', 'database', 'testing', 'debug']
        for keyword in tech_keywords:
            if keyword in content_lower:
                tags.append(keyword)
        
        # æ·»åŠ åŠ¨ä½œæ ‡ç­¾
        action_keywords = ['create', 'fix', 'optimize', 'refactor', 'implement']
        for keyword in action_keywords:
            if keyword in content_lower:
                tags.append(keyword)
        
        return list(set(tags))  # å»é‡
    
    async def create_prompt_library(self, organization_style: str = 'by_purpose') -> Dict:
        """åˆ›å»ºç»“æ„åŒ–çš„æç¤ºè¯åº“"""
        print("ğŸ“š åˆ›å»ºæç¤ºè¯åº“...")
        
        library = {
            'metadata': {
                'created_at': datetime.now().isoformat(),
                'total_prompts': len(self.discovered_prompts),
                'organization_style': organization_style
            },
            'categories': {},
            'prompts': [asdict(prompt) for prompt in self.discovered_prompts]
        }
        
        if organization_style == 'by_purpose':
            library['categories'] = self._organize_by_purpose()
        elif organization_style == 'by_domain':
            library['categories'] = self._organize_by_domain()
        elif organization_style == 'by_complexity':
            library['categories'] = self._organize_by_complexity()
        else:
            library['categories'] = self._organize_hierarchical()
        
        self.prompt_library = library
        return library
    
    def _organize_by_purpose(self) -> Dict:
        """æŒ‰ç›®çš„ç»„ç»‡æç¤ºè¯"""
        categories = {}
        
        for prompt in self.discovered_prompts:
            purpose = prompt.purpose
            if purpose not in categories:
                categories[purpose] = []
            categories[purpose].append(asdict(prompt))
        
        return categories
    
    def _organize_by_domain(self) -> Dict:
        """æŒ‰é¢†åŸŸç»„ç»‡æç¤ºè¯"""
        categories = {}
        
        for prompt in self.discovered_prompts:
            domain = prompt.domain
            if domain not in categories:
                categories[domain] = []
            categories[domain].append(asdict(prompt))
        
        return categories
    
    def _organize_by_complexity(self) -> Dict:
        """æŒ‰å¤æ‚åº¦ç»„ç»‡æç¤ºè¯"""
        categories = {}
        
        for prompt in self.discovered_prompts:
            complexity = prompt.complexity
            if complexity not in categories:
                categories[complexity] = []
            categories[complexity].append(asdict(prompt))
        
        return categories
    
    def _organize_hierarchical(self) -> Dict:
        """åˆ†å±‚ç»„ç»‡æç¤ºè¯"""
        categories = {
            'by_purpose': self._organize_by_purpose(),
            'by_domain': self._organize_by_domain(),
            'by_complexity': self._organize_by_complexity(),
            'by_context': self._organize_by_context_type()
        }
        return categories
    
    def _organize_by_context_type(self) -> Dict:
        """æŒ‰ä¸Šä¸‹æ–‡ç±»å‹ç»„ç»‡æç¤ºè¯"""
        categories = {}
        
        for prompt in self.discovered_prompts:
            context_type = prompt.context_type
            if context_type not in categories:
                categories[context_type] = []
            categories[context_type].append(asdict(prompt))
        
        return categories
    
    async def generate_reuse_templates(self, template_format: str = 'markdown') -> str:
        """ç”Ÿæˆå¯å¤ç”¨çš„æç¤ºè¯æ¨¡æ¿"""
        print("ğŸ› ï¸ ç”Ÿæˆé‡ç”¨æ¨¡æ¿...")
        
        if not self.prompt_library:
            await self.create_prompt_library()
        
        if template_format == 'markdown':
            return self._generate_markdown_templates()
        elif template_format == 'json':
            return json.dumps(self.prompt_library, indent=2, ensure_ascii=False)
        elif template_format == 'yaml':
            return yaml.dump(self.prompt_library, default_flow_style=False, allow_unicode=True)
        else:
            return self._generate_text_templates()
    
    def _generate_markdown_templates(self) -> str:
        """ç”ŸæˆMarkdownæ ¼å¼çš„æ¨¡æ¿"""
        md_content = ["# æç¤ºè¯åº“\n"]
        md_content.append(f"*ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*\n")
        md_content.append(f"*æ€»è®¡æç¤ºè¯: {len(self.discovered_prompts)}*\n\n")
        
        # æŒ‰ç›®çš„åˆ†ç»„æ˜¾ç¤º
        by_purpose = self._organize_by_purpose()
        
        for purpose, prompts in by_purpose.items():
            md_content.append(f"## {purpose.title()} ç›¸å…³æç¤ºè¯\n")
            
            for i, prompt_data in enumerate(prompts, 1):
                prompt = Prompt(**prompt_data)
                md_content.append(f"### {i}. {prompt.source_file}:{prompt.line_number}\n")
                md_content.append(f"**é¢†åŸŸ**: {prompt.domain} | **å¤æ‚åº¦**: {prompt.complexity} | **ä¸Šä¸‹æ–‡**: {prompt.context_type}\n")
                md_content.append(f"**æ ‡ç­¾**: {', '.join(prompt.tags)}\n")
                md_content.append(f"> {prompt.content}\n\n")
                
                # ç”Ÿæˆå¯é‡ç”¨æ¨¡æ¿
                template = self._create_reusable_template(prompt)
                md_content.append(f"**å¯é‡ç”¨æ¨¡æ¿**:\n```\n{template}\n```\n\n")
        
        return '\n'.join(md_content)
    
    def _create_reusable_template(self, prompt: Prompt) -> str:
        """åˆ›å»ºå¯é‡ç”¨çš„æç¤ºè¯æ¨¡æ¿"""
        template = prompt.content
        
        # æ›¿æ¢é¡¹ç›®ç‰¹å®šçš„è·¯å¾„å’Œåç§°ä¸ºå ä½ç¬¦
        template = re.sub(r'/[a-zA-Z_-]+/', '/{PROJECT_PATH}/', template)
        template = re.sub(r'\b[A-Z][a-zA-Z]+Project\b', '{PROJECT_NAME}', template)
        template = re.sub(r'\b[a-z]+@[a-z]+\.[a-z]+\b', '{EMAIL}', template)
        template = re.sub(r'\b\d{4}-\d{2}-\d{2}\b', '{DATE}', template)
        template = re.sub(r'\b\d+\b(?=\s*(?:days?|hours?|minutes?))', '{TIME_VALUE}', template)
        
        # æ·»åŠ ä½¿ç”¨è¯´æ˜
        template += "\n\n---\n*ä½¿ç”¨æ–¹æ³•: å°† {} ä¸­çš„å ä½ç¬¦æ›¿æ¢ä¸ºå®é™…å€¼*"
        
        return template
    
    def _generate_text_templates(self) -> str:
        """ç”Ÿæˆçº¯æ–‡æœ¬æ¨¡æ¿"""
        text_content = ["æç¤ºè¯åº“\n"]
        text_content.append(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        text_content.append(f"æ€»è®¡æç¤ºè¯: {len(self.discovered_prompts)}\n\n")
        
        for i, prompt in enumerate(self.discovered_prompts, 1):
            text_content.append(f"{i}. [{prompt.purpose}] {prompt.source_file}:{prompt.line_number}")
            text_content.append(f"   å†…å®¹: {prompt.content}")
            text_content.append(f"   æ¨¡æ¿: {self._create_reusable_template(prompt)}")
            text_content.append("")
        
        return '\n'.join(text_content)
    
    async def search_prompts(self, criteria: Dict[str, Any]) -> List[Prompt]:
        """æœç´¢æç¤ºè¯"""
        filtered_prompts = self.discovered_prompts.copy()
        
        # æŒ‰ç›®çš„ç­›é€‰
        if 'purpose' in criteria:
            filtered_prompts = [p for p in filtered_prompts if p.purpose == criteria['purpose']]
        
        # æŒ‰é¢†åŸŸç­›é€‰
        if 'domain' in criteria:
            filtered_prompts = [p for p in filtered_prompts if p.domain == criteria['domain']]
        
        # æŒ‰å¤æ‚åº¦ç­›é€‰
        if 'complexity' in criteria:
            filtered_prompts = [p for p in filtered_prompts if p.complexity == criteria['complexity']]
        
        # æŒ‰æ ‡ç­¾ç­›é€‰
        if 'tags' in criteria:
            required_tags = set(criteria['tags'])
            filtered_prompts = [p for p in filtered_prompts if required_tags.intersection(set(p.tags))]
        
        # æŒ‰å…³é”®è¯æœç´¢å†…å®¹
        if 'keyword' in criteria:
            keyword = criteria['keyword'].lower()
            filtered_prompts = [p for p in filtered_prompts if keyword in p.content.lower()]
        
        return filtered_prompts
    
    async def export_prompt_library(self, export_path: str, format_type: str = 'markdown') -> str:
        """å¯¼å‡ºæç¤ºè¯åº“"""
        print(f"ğŸ’¾ å¯¼å‡ºæç¤ºè¯åº“åˆ° {export_path}...")
        
        if format_type == 'markdown':
            content = await self.generate_reuse_templates('markdown')
        elif format_type == 'json':
            content = json.dumps(self.prompt_library, indent=2, ensure_ascii=False)
        elif format_type == 'yaml':
            content = yaml.dump(self.prompt_library, default_flow_style=False, allow_unicode=True)
        else:
            content = await self.generate_reuse_templates('text')
        
        # ç¡®ä¿å¯¼å‡ºç›®å½•å­˜åœ¨
        export_file = Path(export_path)
        export_file.parent.mkdir(parents=True, exist_ok=True)
        
        with open(export_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        return export_path